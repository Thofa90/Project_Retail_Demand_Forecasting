# ğŸ“Œ Project Title

**Grocery/Retail Sales Forecasting â€“ CorporaciÃ³n Favorita Case Study**

â¸»

# ğŸ¯ Project Goal

The objective of this project is to develop a predictive model that accurately forecasts daily product sales across multiple grocery stores. By leveraging historical sales data, store information, and external factors (e.g., holidays, promotions), we aim to create a robust forecasting system that can generalize well to future periods.The project compare ARIMA-based methods, tree-based models (XGBoost), and neural networks (LSTM) to evaluate forecasting accuracy and business applicability.

â¸»

# ğŸ¢ Business Context

CorporaciÃ³n Favorita is one of the largest grocery store chains in Ecuador. With thousands of products and multiple store locations, predicting future sales is a critical task for managing operations efficiently. Accurate forecasts enable the company to:

	â€¢	ğŸ“¦ Optimize inventory â€” ensure products are available when customers need them while minimizing overstock.
	â€¢	ğŸ›’ Reduce waste â€” especially for perishable goods by aligning supply with demand.
	â€¢	ğŸ’° Improve profitability â€” through better pricing, promotions, and stock allocation.
	â€¢	ğŸšš Enhance logistics â€” streamline supply chain management and replenishment scheduling.

â¸»

# ğŸŒ Real-World Application

Sales forecasting plays a crucial role in retail and supply chain optimization. The techniques developed here are directly applicable to:

	â€¢	ğŸª Retail chains managing multiple stores with varied customer demand.
	â€¢	ğŸ¥¦ Supermarkets & groceries aiming to cut food waste and stockouts.
	â€¢	ğŸ“Š E-commerce platforms predicting order volume for better fulfillment planning.
	â€¢	ğŸš¢ Logistics companies optimizing warehouse and delivery schedules.
	â€¢	ğŸ¯ Promotional planning â€” aligning discounts and marketing campaigns with predicted demand peaks.

# ğŸ“‚ Project Structure

1. data_store_sales/.    # Raw CSV files (items.csv, stores.csv, transactions. csv, oil.csv, holidays_events.csv, train.csv, etc.)

2. DataLoad_EDA_Merging.ipynb.    # File 1 - Data loading, cleaning, preprocessing & EDA

3. FeatureEng_BasicModel(ARIMA with exo feature).ipynb   # File 2 - Feature engineering & ARIMA/SARIMAX models

4. XGBOOST_Model.ipynb.    # File 3 - XGBoost baseline + tuned model

5. LSTM_Model.ipynb.    # File 4 - LSTM + tuned LSTM model

6. saved_models/.    # Trained model artifacts (XGBoost, ARIMA, LSTM)

7. README.md.    # Project documentation

# ğŸ“Š Dataset

The datasets are stored in the data_store_sales/ folder.

	â€¢	Items.csv â†’ Item details
	â€¢	Stores.csv â†’ Store details
	â€¢	Transactions.csv â†’ Daily transaction counts
	â€¢	Oil.csv â†’ Daily oil prices (external factor)
	â€¢	Holidays_events.csv â†’ Special events and holidays
	â€¢	Train.csv â†’ Main sales data (store_nbr, item_nbr, date, unit_sales, onpromotion)

# ğŸ“‚ Workflow Overview

**1. Importing Data**

	â€¢	Items: Product information including perishability and family classification.
	â€¢	Stores: Store details including location and type.
	â€¢	Transactions: Daily transaction counts per store.
	â€¢	Oil: Historical oil prices (as a macroeconomic factor).
	â€¢	Holidays Event: National & local holidays with event types.
	â€¢	Train: Historical sales data.
	â€¢	Filtering: Data limited to Guayas state and top 3 product families.

â¸»

**2. Preprocessing**

	1.	Dealing with Missing Values â€“ Filling or removing null entries.
	2.	Converting Negative Sales to Zero â€“ Fixing incorrect data entries.
	3.	Outlier Analysis â€“ Identifying extreme values in sales & transactions.
	4.	Filling Missing Dates with Zero Sales â€“ Ensuring continuous daily data.
	5.	Merging Full Range Dataset â€“ Combining:
	â€¢	Outlier-adjusted sales
	â€¢	Oil prices
	â€¢	Transactions
	â€¢	Holidays

â¸»

**3. Exploratory Data Analysis (EDA)**

	1.	Time-Based Features â€“ Trends in sales over years, months, and days.
	2.	Impact of Holidays â€“ Analyzing how holidays influence sales volume.
	3.	Oil Price Impact â€“ Correlation between oil price fluctuations and sales.
	4.	Perishable vs Non-Perishable Sales â€“ Sales patterns by product type.
	5.	Store vs Item Analysis â€“ Item-level sales performance per store.
	6.	Transaction vs Sales Analysis â€“ Relationship between transaction count and unit sales.
	7.	Weekly Transaction Volume â€“ Identifying peak shopping days.
	8.	Holiday Sales Impact â€“ Comparing transactions on holidays vs non-holidays.
	9.	Basket Size Distribution â€“ Average items per transaction, identifying bulk-buying behavior.

**4. ğŸ“Š Key Insights from EDA**

	â€¢	Certain stores dominate sales volume, while others serve fewer but larger transactions.
	â€¢	Perishable items have lower total sales compared to non-perishables.
	â€¢	Holidays tend to increase both transactions and sales, but the effect varies by store.
	â€¢	Oil price changes show potential indirect influence on consumer spending.
	â€¢	Bulk buying is more common in specific stores, impacting stock planning.

**5. Feature Engineering & ARIMA Models with features**

	â€¢	Created time-based features (day, week, month, year, etc.)
	â€¢	Built lag features (1, 7, 14, 30, 60 days)
	â€¢	Rolling & exponentially weighted averages
	â€¢	Promotion effects and external drivers (oil, holidays)
	â€¢	Implemented ARIMA, ARIMAX, SARIMAX, Holt-Winters
	â€¢	Reported metrics (MAE, RMSE, MAPE)

**6. XGBoost Model**

	â€¢	Baseline XGBoost with default params
	â€¢	Hyperparameter tuning with RandomizedSearchCV
	â€¢	Saved tuned XGBoost model to saved_models/
	â€¢	Evaluation: MAE, RMSE, RÂ², MAPE, sMAPE, MASE

**7.  LSTM & Tuned LSTM Model**

	â€¢	Scaled data with MinMaxScaler / StandardScaler
	â€¢	Sequence building (lookback windows of 30 & 60 days)
	â€¢	Baseline LSTM and tuned LSTM (layers, units, dropout, learning rate)
	â€¢	Hyperparameter tuning with grid search (window size Ã— units Ã— depth)
	â€¢	Compared baseline vs tuned model performance
	â€¢	Plotted actual vs predicted sales for last 30 & 90 days

**8. ğŸ“ˆ Evaluation Metrics**

Report includes:

	â€¢	MAE (Mean Absolute Error)
	â€¢	RMSE (Root Mean Squared Error)
	â€¢	RÂ² (Coefficient of Determination)
	â€¢	MAPE (Mean Absolute Percentage Error)
	â€¢	sMAPE (Symmetric MAPE)
	â€¢	MASE (Mean Absolute Scaled Error)

**9. ğŸš€ Key Findings & Recommendations**

	â€¢	ARIMA/SARIMAX captured seasonality but struggled with external regressors.
	â€¢	XGBoost handled multiple features well and gave strong baseline results.
	â€¢	LSTM (tuned) showed improvement in short-term predictions but still had difficulty capturing high variance in sales.

**Business Recommendation:**

	â€¢	Use XGBoost for operational daily forecasts (robust, handles features well).
	â€¢	Use LSTM for items with strong temporal dependencies and retrain frequently.

**10. âœ… Conclusion**

This project demonstrates how classical models (ARIMA), tree-based models (XGBoost), and deep learning (LSTM) can be applied to real-world retail forecasting.
The experiments highlight the trade-offs between interpretability, accuracy, and computational complexity.

# Model Comparison

## ğŸ“Š Model Comparison

| Model              | MAE   | RMSE  | RÂ²      | Strengths | Weaknesses | Business Implication |
|---------------------|-------|-------|---------|-----------|------------|----------------------|
| **ARIMA**           | 1.000 | 1.092 | -2.188  | Simple, fast, captures autocorrelation | No external drivers, misses events | Too inaccurate â†’ over/understocking risk |
| **ARIMAX**          | 0.613 | 0.681 | -0.242  | Uses promotions, holidays, lags | Still weak for irregular spikes | Best traditional model, actionable forecasts |
| **SARIMAX**         | 0.616 | 0.724 | -0.403  | Adds seasonality | Seasonal cycles not strong here | No gain over ARIMAX, unnecessary complexity |
| **Holt-Winters**    | 2.547 | 2.640 | -17.641 | Smooths trend/seasonality | No exogenous features, misses spikes | Unusable for sporadic sales, flat forecasts |
| **XGBoost (Baseline)** | 1.437 | 4.792 | 0.696 | Captures non-linear effects | Higher RMSE baseline | Useful but needs tuning |
| **XGBoost (Tuned)** | 1.441 | 4.738 | 0.703 | Better RMSE, higher RÂ² | MAE unchanged | Stronger than baseline, learns exogenous impact |
| **LSTM (Previous)** | 0.642 | 0.823 | -0.812 | Captures sequence memory | Struggles with variance | Moderate accuracy, unstable |
| **LSTM (Tuned)**    | 0.365 | 0.464 | -1.389 | Lowest MAE/RMSE | Negative RÂ², poor generalization | Good for short-term, unreliable long-term |


## âœ… Recommendation

Based on the comparison:

- **Best Overall Traditional Model â†’ ARIMAX**
  - Lowest MAE & RMSE among classical models.
  - Incorporates external drivers (promotions, holidays, lags).
  - Reliable for operational business forecasting (inventory planning, promotions, staffing).

- **Best ML Model â†’ Tuned XGBoost**
  - Higher RÂ² (better fit) and lower RMSE than baseline.
  - Learns non-linear effects from external features.
  - Scales better than ARIMA-family models for large datasets.

- **Deep Learning Model (LSTM)**
  - Tuned LSTM achieved lowest MAE/RMSE, but negative RÂ² indicates poor generalization.
  - Useful for **short-term forecasts**, but not stable for production.

- **âœ… Takeaway:**  
  - Use **ARIMAX** if you want interpretability and external features matter.  
  - Use **XGBoost** if dataset is larger and has non-linear relationships.  
  - Use **LSTM** when sequential dependencies are critical (but validate carefully).  

  ## ğŸ” Model Selection Flow

When deciding which forecasting model to use:
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Size of Data?    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Small / Medium Data             Large / Complex Data
â”‚                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ARIMAX    â”‚                 â”‚   XGBoost    â”‚
â”‚ (best for   â”‚                 â”‚ (handles     â”‚
â”‚ explainable â”‚                 â”‚ non-linear   â”‚
â”‚ forecasts)  â”‚                 â”‚ features)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                               â”‚
â”‚                               â”‚
â”‚                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚  Stable,     â”‚                â”‚ Tuned for   â”‚
â”‚ interpretableâ”‚                â”‚ better fit  â”‚
â”‚ forecasts    â”‚                â”‚ on big data â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Sequential /    â”‚
â”‚  Short-term Data? â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚.        |
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚    LSTM     â”‚
â”‚ (captures   â”‚
â”‚ sequence &  â”‚
â”‚ memory)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    

### ğŸš€ Practical Usage

- Use **ARIMAX** as the baseline model for explainability and operational use.  
- For improved performance on larger datasets, prefer **Tuned XGBoost**.  
- Keep **LSTM** for experimental or short-term forecasting â€” but not as the main business driver.  
- Consider **hybrid models**:  
  - ARIMAX for stable baseline forecasts.  
  - ML models (XGBoost/LightGBM) for residual corrections and anomaly handling.

# ğŸ’¾ Model Saving & Loading


All trained models are saved in the project root (e.g., saved_models/xgboost_tuned.pkl, lstm_tuned.h5).

# ğŸ› ï¸ Requirements

âœ… With this file in your project root, anyone can install everything with:

pip install -r requirements.txt

**Core Python packages**

numpy
pandas
scipy

**Visualization**

matplotlib
seaborn

**Time Series Models**

statsmodels

**Machine Learning**

scikit-learn
xgboost

**Deep Learning**

tensorflow

**Jupyter Notebook**

notebook
ipykernel